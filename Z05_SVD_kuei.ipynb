{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6:  Topic Modeling with Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Semantic Analysis (LSA) is a method for finding latent similarities between documents treated as a bag of words by using a low rank approximation. It is used for document classification, clustering and retrieval. For example, LSA can be used to search for prior art given a new patent application. In this homework, we will implement a small library for simple latent semantic analysis as a practical example of the application of SVD. The ideas are very similar to PCA. SVD is also used in recommender systems in an similar fashion (for an SVD-based recommender system library, see [Surpise](http://surpriselib.com). \n",
    "\n",
    "We will implement a toy example of LSA to get familiar with the ideas. If you want to use LSA or similar methods for statistical language analysis, the most efficient Python libraries are probably [gensim](https://radimrehurek.com/gensim/) and [spaCy](https://spacy.io) - these also provide an online algorithm - i.e. the training information can be continuously updated. Other useful functions for processing natural language can be found in the [Natural Language Toolkit](http://www.nltk.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The SVD from scipy.linalg performs a full decomposition, which is inefficient since we only need to decompose until we get the first k singluar values. If the SVD from `scipy.linalg` is too slow, please use the `svds` function in `scipy.sparse.linalg` or the `sparsesvd` function from the [sparsesvd](https://pypi.python.org/pypi/sparsesvd/) package to perform SVD instead.  You can install in the usual way with \n",
    "```\n",
    "!pip install sparsesvd\n",
    "```\n",
    "\n",
    "Then import the following\n",
    "```python\n",
    "from sparsesvd import sparsesvd \n",
    "from scipy.sparse import csc_matrix \n",
    "```\n",
    "\n",
    "and use as follows\n",
    "```python\n",
    "sparsesvd(csc_matrix(M), k=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### basic tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "import scipy.stats  as stats\n",
    "\n",
    "import itertools as it\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "import toolz as tz\n",
    "import toolz.curried as c\n",
    "\n",
    "### import data\n",
    "import pickle\n",
    "\n",
    "### sparce matrix\n",
    "from sparsesvd    import sparsesvd \n",
    "from scipy.sparse import csc_matrix \n",
    "\n",
    "### plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### func testing\n",
    "import doctest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a name=\"toc\"></a>\n",
    "- [Question 01](#Q01)\n",
    "- [Question 02](#Q02)\n",
    "- [Question 03](#Q03)\n",
    "- [Question 04](#Q04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Question 01 <a name=\"Q01\"></a>\n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1 (20 points)**.  Calculating pairwise distance matrices.\n",
    "\n",
    "Suppose we want to construct a distance matrix between the rows of a matrix. For example, given the matrix \n",
    "\n",
    "```python\n",
    "M = np.array([[1,2,3],[4,5,6]])\n",
    "```\n",
    "\n",
    "the distance matrix using Euclidean distance as the measure would be\n",
    "```python\n",
    "[[ 0.000  1.414  2.828]\n",
    " [ 1.414  0.000  1.414]\n",
    " [ 2.828  1.414  0.000]] \n",
    "```\n",
    "if $M$ was a collection of column vectors.\n",
    "\n",
    "Write a function to calculate the pairwise-distance matrix given the matrix $M$ and some arbitrary distance function. Your functions should have the following signature:\n",
    "```\n",
    "def func_name(M, distance_func):\n",
    "    pass\n",
    "```\n",
    "\n",
    "0. [Write a distance function for the Euclidean, squared Euclidean and cosine measures.](#Q10)\n",
    "1. [Write the function using looping for M as a collection of row vectors.](#Q11)\n",
    "2. [Write the function using looping for M as a collection of column vectors.](#Q12)\n",
    "3. [Write the function using broadcasting for M as a collection of row vectors.](#Q13)\n",
    "4. [Write the function using broadcasting for M as a collection of column vectors.](#Q14)\n",
    "\n",
    "For 3 and 4, try to avoid using transposition (but if you get stuck, there will be no penalty for using transposition). Check that all four functions give the same result when applied to the given matrix $M$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10 Write a distance function for the Euclidean, squared Euclidean and cosine measures. <a name = \"Q10\"></a>\n",
    "[Back to Question 01](#Q01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_euclidean_sq(x, y = None, axis = 0):\n",
    "    \"\"\"calculate squared Euclidean distance of numpy vector x and y; if only one vector\n",
    "    \n",
    "    >>> x = np.array([3, 4])\n",
    "    >>> y = np.array([0, 0])\n",
    "    >>> z = np.array([-2, -8])\n",
    "    >>> dist_euclidean_sq(x)\n",
    "    25.0\n",
    "    >>> dist_euclidean_sq(x, y)\n",
    "    25.0\n",
    "    >>> dist_euclidean_sq(y, x)\n",
    "    25.0\n",
    "    >>> dist_euclidean_sq(x, z)\n",
    "    169.0\n",
    "    \"\"\"\n",
    "    ### coerce the type to float\n",
    "    x = x.copy().astype(np.float)\n",
    "    \n",
    "    ### calculate squared euclidean distance\n",
    "    if y is None:\n",
    "        # one vector only\n",
    "        return(np.sum(np.square(x), axis = axis))\n",
    "    else:\n",
    "        # input two vectors\n",
    "        return(np.sum(np.square(x - y), axis = axis))\n",
    "    \n",
    "def dist_euclidean(x, y = None, axis = 0):\n",
    "    \"\"\"calculate Euclidean distance of numpy vector x and y\n",
    "    \n",
    "    >>> x = np.array([3, 4])\n",
    "    >>> y = np.array([0, 0])\n",
    "    >>> z = np.array([-2, -8])\n",
    "    >>> dist_euclidean(x)\n",
    "    5.0\n",
    "    >>> dist_euclidean(x, y)\n",
    "    5.0\n",
    "    >>> dist_euclidean(y, x)\n",
    "    5.0\n",
    "    >>> dist_euclidean(x, z)\n",
    "    13.0\n",
    "    \"\"\"\n",
    "    dist_sq = dist_euclidean_sq(x, y, axis = axis)\n",
    "    return(dist_sq**0.5)\n",
    "\n",
    "def dist_cosine(x, y = None):\n",
    "    \"\"\"calculate cosince distance of input vectors\n",
    "    >>> x = np.array([1, 1])\n",
    "    >>> y = np.array([1, 0]) # x axis\n",
    "    \n",
    "    >>> d = dist_cosine(x, y)\n",
    "    >>> np.allclose(d, np.cos(np.pi / 4)) # expect: 45 degree\n",
    "    True\n",
    "    \n",
    "    >>> d = dist_cosine(y, x)             # check d(x, y) = d(y, x)\n",
    "    >>> np.allclose(d, np.cos(np.pi / 4)) # expect: 45 degree\n",
    "    True\n",
    "    \n",
    "    >>> x = np.array([1, 3**0.5])\n",
    "    >>> y = np.array([1, 0]) # x axis\n",
    "    >>> d = dist_cosine(x, y)\n",
    "    >>> np.allclose(d, np.cos(np.pi / 3)) # expect: 60 degree\n",
    "    True\n",
    "    \n",
    "    >>> x = np.array([1, 3**0.5])\n",
    "    >>> y = np.array([0, 1]) # y axis\n",
    "    >>> d = dist_cosine(x, y)\n",
    "    >>> np.allclose(d, np.cos(np.pi / 6)) # expect: 30 degree\n",
    "    True\n",
    "    \"\"\"\n",
    "    \n",
    "    dist = np.dot(x, y) / np.dot(x, x)**0.5 / np.dot(y, y)**0.5     \n",
    "    return dist\n",
    "\n",
    "\n",
    "### test each function; if passed, no output from the run_docstring_examples\n",
    "doctest.run_docstring_examples(dist_euclidean_sq, globals())\n",
    "doctest.run_docstring_examples(dist_euclidean,    globals())\n",
    "doctest.run_docstring_examples(dist_cosine,       globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11 Write the function using looping for M as a collection of row vectors. <a name = \"Q11\"></a>\n",
    "[Back to Question 01](#Q01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pdist_row_loop(M, distance_func):\n",
    "    \"\"\"calculate the pairwise-distance matrix given the matrix M and some arbitrary distance function\n",
    "    \n",
    "    Notes:\n",
    "    - M is a collection of row vectors\n",
    "    - using looping instead of broadcasting\n",
    "    \n",
    "    >>> M = np.array([[1,2,3],[4,5,6]])\n",
    "    >>> dist = my_pdist_row_loop(M.T, dist_euclidean) # results\n",
    "    >>> dist_exp = np.array([                         # expected\n",
    "    ... [ 0.000,  1.414,  2.828],\n",
    "    ... [ 1.414,  0.000,  1.414],\n",
    "    ... [ 2.828,  1.414,  0.000]])\n",
    "    \n",
    "    >>> dist_round = np.round(dist, decimals = 3)\n",
    "    >>> np.allclose(dist_round, dist_exp)\n",
    "    True\n",
    "    \"\"\"\n",
    "    ### initialization\n",
    "    nrow, ncol = M.shape\n",
    "    idx        = np.arange(nrow)\n",
    "    mat_dist   = np.zeros((nrow, nrow))\n",
    "    \n",
    "    ### loop through row pairs\n",
    "    for idx01, idx02 in it.combinations(idx, 2):\n",
    "        dist = distance_func(M[idx01], M[idx02])\n",
    "        mat_dist[idx01, idx02] = dist\n",
    "        mat_dist[idx02, idx01] = dist\n",
    "        \n",
    "    return mat_dist\n",
    "\n",
    "### test each function; if passed, no output from the run_docstring_examples\n",
    "doctest.run_docstring_examples(my_pdist_row_loop, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12 Write the function using looping for M as a collection of column vectors. <a name = \"Q12\"></a>\n",
    "[Back to Question 01](#Q01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pdist_col_loop(M, distance_func):\n",
    "    \"\"\"calculate the pairwise-distance matrix given the matrix M and some arbitrary distance function\n",
    "    \n",
    "    Notes:\n",
    "    - M is a collection of \"column\" vectors\n",
    "    - using looping instead of broadcasting\n",
    "    \n",
    "    >>> M = np.array([[1,2,3],[4,5,6]])\n",
    "    >>> dist = my_pdist_col_loop(M, dist_euclidean) # results\n",
    "    >>> dist_exp = np.array([                         # expected\n",
    "    ... [ 0.000,  1.414,  2.828],\n",
    "    ... [ 1.414,  0.000,  1.414],\n",
    "    ... [ 2.828,  1.414,  0.000]])\n",
    "    \n",
    "    >>> dist_round = np.round(dist, decimals = 3)\n",
    "    >>> np.allclose(dist_round, dist_exp)\n",
    "    True\n",
    "    \"\"\"\n",
    "    return my_pdist_row_loop(M.T, distance_func)\n",
    "\n",
    "### test each function; if passed, no output from the run_docstring_examples\n",
    "doctest.run_docstring_examples(my_pdist_col_loop, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q13 Write the function using broadcasting for M as a collection of row vectors.. <a name = \"Q13\"></a>\n",
    "[Back to Question 01](#Q01)\n",
    "\n",
    "For 3 and 4, try to avoid using transposition (but if you get stuck, there will be no penalty for using transposition). Check that all four functions give the same result when applied to the given matrix $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pdist_row_bcast(M, distance_func):\n",
    "    \"\"\"calculate the pairwise-distance matrix given the matrix M and some arbitrary distance function\n",
    "    \n",
    "    Notes:\n",
    "    - M is a collection of \"column\" vectors\n",
    "    - using broadcasting instead of looping\n",
    "    \n",
    "    >>> M = np.array([[1,2,3],[4,5,6]])                # collection of col vectors\n",
    "    >>> dist = my_pdist_row_bcast(M.T, dist_euclidean) # results\n",
    "    >>> dist_exp = np.array([                          # expected\n",
    "    ... [ 0.000,  1.414,  2.828],\n",
    "    ... [ 1.414,  0.000,  1.414],\n",
    "    ... [ 2.828,  1.414,  0.000]])\n",
    "    \n",
    "    >>> dist_round = np.round(dist, decimals = 3)\n",
    "    >>> np.allclose(dist_round, dist_exp)\n",
    "    True\n",
    "    \"\"\"\n",
    "    return distance_func(M[:, np.newaxis], M, axis = 2)\n",
    "    \n",
    "\n",
    "### test each function; if passed, no output from the run_docstring_examples\n",
    "doctest.run_docstring_examples(my_pdist_row_bcast, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q14 Write the function using broadcasting for M as a collection of column vectors. <a name = \"Q14\"></a>\n",
    "[Back to Question 01](#Q01)\n",
    "\n",
    "For 3 and 4, try to avoid using transposition (but if you get stuck, there will be no penalty for using transposition). Check that all four functions give the same result when applied to the given matrix $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pdist_col_bcast(M, distance_func):\n",
    "    \"\"\"calculate the pairwise-distance matrix given the matrix M and some arbitrary distance function\n",
    "    \n",
    "    Notes:\n",
    "    - M is a collection of \"column\" vectors\n",
    "    - using broadcasting instead of looping\n",
    "    \n",
    "    >>> M = np.array([[1,2,3],[4,5,6]])                # collection of col vectors\n",
    "    >>> dist = my_pdist_col_bcast(M, dist_euclidean) # results\n",
    "    >>> dist_exp = np.array([                          # expected\n",
    "    ... [ 0.000,  1.414,  2.828],\n",
    "    ... [ 1.414,  0.000,  1.414],\n",
    "    ... [ 2.828,  1.414,  0.000]])\n",
    "    \n",
    "    >>> dist_round = np.round(dist, decimals = 3)\n",
    "    >>> np.allclose(dist_round, dist_exp)\n",
    "    True\n",
    "    \"\"\"\n",
    "    return my_pdist_row_bcast(M.T, distance_func)\n",
    "    \n",
    "\n",
    "### test each function; if passed, no output from the run_docstring_examples\n",
    "doctest.run_docstring_examples(my_pdist_col_bcast, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Question 02 <a name=\"Q02\"></a>\n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2 (20 points)**. Write 3 functions to calculate the term frequency (tf), the inverse document frequency (idf) and the product (tf-idf). Each function should take a single argument `docs`, which is a dictionary of (key=identifier, value=document text) pairs, and return an appropriately sized array. Convert '-' to ' ' (space), remove punctuation, convert text to lowercase and split on whitespace to generate a collection of terms from the document text.\n",
    "\n",
    "- tf = the number of occurrences of term $i$ in document $j$\n",
    "- idf = $\\log \\frac{n}{1 + \\text{df}_i}$ where $n$ is the total number of documents and $\\text{df}_i$ is the number of documents in which term $i$ occurs.\n",
    "\n",
    "Print the table of tf-idf values for the following document collection\n",
    "\n",
    "```\n",
    "s1 = \"The quick brown fox\"\n",
    "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
    "s3 = \"The the the lazy dog elephant.\"\n",
    "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
    "\n",
    "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write 3 functions to calculate the term frequency (tf), the inverse document frequency (idf) and the product (tf-idf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2gen(string):\n",
    "    \"\"\"convert a string to a word generator\n",
    "    \n",
    "    Convert '-' to ' ' (space), remove punctuation, convert text to lowercase and \n",
    "    split on whitespace to generate a collection of terms from the document text\n",
    "    \n",
    "    >>> string = \"\"\n",
    "    >>> list(str2gen(string))                       \n",
    "    []\n",
    "    \n",
    "    >>> string = \"The quick brown fox\"\n",
    "    >>> list(str2gen(string))\n",
    "    ['the', 'quick', 'brown', 'fox']\n",
    "    \n",
    "    >>> string = \"This is stRing example....wow!!!\"\n",
    "    >>> list(str2gen(string))\n",
    "    ['this', 'is', 'string', 'example', 'wow']\n",
    "    \"\"\"\n",
    "    # translate table to convert punctuation into whitespace \n",
    "    # punctuation: !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\n",
    "    transtab = str.maketrans(punctuation, \" \" * len(punctuation))\n",
    "    \n",
    "    # process input string\n",
    "    str_lst = tz.pipe(\n",
    "        string,\n",
    "        lambda x: x.lower(),             # convert text to lowercase\n",
    "        lambda x: x.translate(transtab), # Convert punctuation to whitespace\n",
    "        lambda x: x.split(\" \"),          # split on whitespace\n",
    "        c.filter(None)                   # filter empty string\n",
    "    ) # end pipe\n",
    "    \n",
    "    return(str_lst)\n",
    "    \n",
    "\n",
    "def get_tf(docs):\n",
    "    \"\"\"calculate the term frequency (tf) from docs, which is \n",
    "    a dictionary of (key=identifier, value=document text) pairs, \n",
    "    and return an appropriately sized array\n",
    "    \n",
    "    >>> docs = {'x': \"A A A\", 'y': \"A B C\"}\n",
    "    >>> doc_tf = get_tf(docs)\n",
    "    \n",
    "    >>> list(doc_tf.index) # row: terms\n",
    "    ['a', 'b', 'c']\n",
    "    \n",
    "    >>> list(doc_tf.columns.values) # col: key of docs (docs identifiers)\n",
    "    ['x', 'y']\n",
    "    \"\"\"\n",
    "    ### counters\n",
    "    tf_count = dict()\n",
    "    for k, v in docs.items():\n",
    "        str_lst = list(str2gen(v))\n",
    "        tf_count[k] = Counter(str_lst)\n",
    "    \n",
    "    ### get all terms (words) and docs identifiers\n",
    "    # get all terms in docs\n",
    "    terms  = tz.pipe(\n",
    "        tf_count,                       # input dict of (str, Counter)\n",
    "        lambda x: x.values(),           # collection of Counters\n",
    "        c.map(lambda x: x.elements()),  # get elements of each Counter\n",
    "        it.chain.from_iterable          # merge collection of elements together\n",
    "    ) # end pipe\n",
    "    terms = list(set(terms))            # remove duplicates\n",
    "    \n",
    "    # get docs identifiers\n",
    "    doc_id = list(tf_count.keys())\n",
    "    \n",
    "    ### initialize pandas data frame\n",
    "    ### row: term, col: doc id \n",
    "    tf_df = pd.DataFrame(0, index = terms, columns = doc_id)\n",
    "    \n",
    "    ### convert Counters to matrix / dataframe\n",
    "    for idx, cnt in tf_count.items():\n",
    "        for term, val in cnt.items():\n",
    "            tf_df.loc[term, idx] = val\n",
    "    \n",
    "    ### arrange and return\n",
    "    tf_df.sort_index(axis = 0, inplace = True)\n",
    "    tf_df.sort_index(axis = 1, inplace = True)\n",
    "    \n",
    "    return tf_df\n",
    "    \n",
    "\n",
    "def get_idf(docs):\n",
    "    \"\"\"idf = log (n / (1 + df_i)) where \n",
    "    - n    is the total number of documents and \n",
    "    - df_i is the number of documents in which term i occurs.\n",
    "    \"\"\"\n",
    "    ### get tf matrix\n",
    "    tf_df = get_tf(docs)\n",
    "    \n",
    "    ### nrow = number of terms\n",
    "    ### ncol = number of documents\n",
    "    nrow, ncol = tf_df.shape\n",
    "    \n",
    "    ### calculate \n",
    "    df = tf_df.apply(np.sum, axis = 1)\n",
    "    \n",
    "    # log (n / (1 + df_i)\n",
    "    return np.log(ncol / (1 + df))\n",
    "\n",
    "def get_tf_idf(docs):\n",
    "    \"\"\"get product of tf and idf\"\"\"\n",
    "    ### get tf and idf\n",
    "    doc_tf  = get_tf(docs)\n",
    "    doc_idf = get_idf(docs)\n",
    "    \n",
    "    ### calculate the product (tf-idf)\n",
    "    res = np.array(doc_tf).T @ np.array(doc_idf).reshape(-1, 1)\n",
    "    return(res)\n",
    "\n",
    "### test each function; if passed, no output from the run_docstring_examples\n",
    "doctest.run_docstring_examples(str2gen, globals())\n",
    "doctest.run_docstring_examples(get_tf,  globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"The quick brown fox\"\n",
    "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
    "s3 = \"The the the lazy dog elephant.\"\n",
    "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
    "\n",
    "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get tf, idf, and product(tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tf  = get_tf(docs)\n",
    "doc_idf = get_idf(docs)\n",
    "doc_tf_idf = get_tf_idf(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          s1  s2  s3  s4\n",
      "brown      1   1   0   0\n",
      "dog        0   0   1   1\n",
      "elephant   0   0   1   1\n",
      "fox        1   1   0   0\n",
      "jumps      0   4   0   0\n",
      "lazy       0   0   1   0\n",
      "lion       0   0   0   1\n",
      "over       0   1   0   0\n",
      "peacock    0   0   0   1\n",
      "quick      1   0   0   0\n",
      "the        1   1   3   5\n",
      "tiger      0   0   0   1\n"
     ]
    }
   ],
   "source": [
    "print(doc_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown       0.287682\n",
      "dog         0.287682\n",
      "elephant    0.287682\n",
      "fox         0.287682\n",
      "jumps      -0.223144\n",
      "lazy        0.693147\n",
      "lion        0.693147\n",
      "over        0.693147\n",
      "peacock     0.693147\n",
      "quick       0.693147\n",
      "the        -1.011601\n",
      "tiger       0.693147\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(doc_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25691041]\n",
      " [-0.63566379]\n",
      " [-1.76629141]\n",
      " [-2.40319887]]\n"
     ]
    }
   ],
   "source": [
    "print(doc_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Question 03 <a name=\"Q03\"></a>\n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3 (20 points)**. \n",
    "\n",
    "1. Write a function that takes a matrix $M$ and an integer $k$ as arguments, and reconstructs a reduced matrix using only the $k$ largest singular values. Use the `scipy.linagl.svd` function to perform the decomposition. This is the least squares approximation to the matrix $M$ in $k$ dimensions.\n",
    "\n",
    "2. Apply the function you just wrote to the following term-frequency matrix for a set of $9$ documents using $k=2$ and print the reconstructed matrix $M'$.\n",
    "```\n",
    "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "       [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "       [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
    "       [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
    "```\n",
    "\n",
    "3. Calculate the pairwise correlation matrix for the original matrix M and the reconstructed matrix using $k=2$ singular values (you may use [scipy.stats.spearmanr](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html) to do the calculations). Consider the fist 5 sets of documents as one group $G1$ and the last 4 as another group $G2$ (i.e. first 5 and last 4 columns). What is the average within group correlation for $G1$, $G2$ and the average cross-group correlation for G1-G2 using either $M$ or $M'$. (Do not include self-correlation in the within-group calculations.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Write function that perform SVD](#Q31)\n",
    "2. [Apply the function to the term-frequency matrix](#Q32)\n",
    "3. [Calculate pairwise correlation matrix for the original matrix and the reconstructed matrix](#Q33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name = \"Q31\"></a> Q31. Write a function that takes a matrix $M$ and an integer $k$ as arguments, and reconstructs a reduced matrix using only the $k$ largest singular values. Use the `scipy.linagl.svd` function to perform the decomposition. This is the least squares approximation to the matrix $M$ in $k$ dimensions. \n",
    "[Back to Question 03](#Q03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_matrix(M, k):\n",
    "    \"\"\"reconstructs a reduced matrix using only the k largest singular values\"\"\"\n",
    "    u, s, vt = la.svd(M)\n",
    "    return u[:, :k] @ np.diag(s)[:k, :k] @ vt[:k, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name = \"Q32\"></a> Q32. Apply the function you just wrote to the following term-frequency matrix for a set of $9$ documents using $k=2$ and print the reconstructed matrix $M'$. \n",
    "[Back to Question 03](#Q03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 9)\n"
     ]
    }
   ],
   "source": [
    "M = np.array([\n",
    "    [1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
    "\n",
    "print(M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 9)\n",
      "[[ 0.16205797  0.40049828  0.37895454  0.46756626  0.17595367 -0.05265495\n",
      "  -0.11514284 -0.15910198 -0.09183827]\n",
      " [ 0.14058529  0.36980077  0.32899603  0.40042722  0.16497247 -0.03281545\n",
      "  -0.07056857 -0.09676827 -0.04298073]\n",
      " [ 0.15244948  0.50500444  0.35793658  0.41010678  0.23623173  0.02421652\n",
      "   0.05978051  0.0868573   0.12396632]\n",
      " [ 0.25804933  0.84112343  0.60571995  0.69735717  0.39231795  0.03311801\n",
      "   0.08324491  0.12177239  0.18737973]\n",
      " [ 0.44878975  1.23436483  1.0508615   1.26579559  0.55633139 -0.07378998\n",
      "  -0.15469383 -0.20959816 -0.04887954]\n",
      " [ 0.15955428  0.5816819   0.37521897  0.41689768  0.27654052  0.05590374\n",
      "   0.1322185   0.18891146  0.21690761]\n",
      " [ 0.15955428  0.5816819   0.37521897  0.41689768  0.27654052  0.05590374\n",
      "   0.1322185   0.18891146  0.21690761]\n",
      " [ 0.21846278  0.54958058  0.51096047  0.62805802  0.24253607 -0.06541098\n",
      "  -0.14252146 -0.19661186 -0.1079133 ]\n",
      " [ 0.09690639  0.53206438  0.22991365  0.21175363  0.26652513  0.13675618\n",
      "   0.31462078  0.44444058  0.42496948]\n",
      " [-0.06125388  0.23210821 -0.1388984  -0.26564589  0.14492549  0.24042105\n",
      "   0.54614717  0.7673742   0.66370933]\n",
      " [-0.06467702  0.33528115 -0.14564055 -0.30140607  0.20275641  0.30572612\n",
      "   0.69489337  0.97661121  0.84874969]\n",
      " [-0.04308204  0.25390566 -0.09666695 -0.20785821  0.1519134   0.22122703\n",
      "   0.50294488  0.70691163  0.6155044 ]]\n"
     ]
    }
   ],
   "source": [
    "M_red = reduced_matrix(M, 2)\n",
    "\n",
    "print(M_red.shape)\n",
    "print(M_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name = \"Q33\"></a> Q33. Calculate the pairwise correlation matrix for the original matrix M and the reconstructed matrix using $k=2$ singular values (you may use [scipy.stats.spearmanr](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html) to do the calculations). Consider the fist 5 sets of documents as one group $G1$ and the last 4 as another group $G2$ (i.e. first 5 and last 4 columns). What is the average within group correlation for $G1$, $G2$ and the average cross-group correlation for G1-G2 using either $M$ or $M'$. (Do not include self-correlation in the within-group calculations.).\n",
    "[Back to Question 03](#Q03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using original matrix M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the group correlation within G1 (`rho_g1`), within G2  (`rho_g2`), and cross-group correlation (`rho_g12`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "(4, 4)\n",
      "(5, 4)\n"
     ]
    }
   ],
   "source": [
    "### calculate pairwise corelation\n",
    "rho, pval = stats.spearmanr(M)\n",
    "\n",
    "### get within / cross correlation\n",
    "rho_g1  = rho[:5, :5]\n",
    "rho_g2  = rho[5:, 5:]\n",
    "rho_g12 = rho[:5, 5:]\n",
    "\n",
    "print(rho_g1.shape)\n",
    "print(rho_g2.shape)\n",
    "print(rho_g12.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average within / cross group correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within G1   0.010577686629862793\n",
      "within G2   0.43511771481980627\n",
      "cross G1-G2 -0.3504857009661986\n"
     ]
    }
   ],
   "source": [
    "idx = np.triu_indices(5, 1)\n",
    "print(\"within G1  \", np.mean(rho_g1[idx]))\n",
    "\n",
    "idx = np.triu_indices(4, 1)\n",
    "print(\"within G2  \", np.mean(rho_g2[idx]))\n",
    "\n",
    "print(\"cross G1-G2\", np.mean(rho_g12[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using reconstructed matrix with k = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the group correlation within G1 (`rho_g1`), within G2  (`rho_g2`), and cross-group correlation (`rho_g12`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "(4, 4)\n",
      "(5, 4)\n"
     ]
    }
   ],
   "source": [
    "### calculate pairwise corelation\n",
    "rho, pval = stats.spearmanr(M_red)\n",
    "\n",
    "### get within / cross correlation\n",
    "rho_g1  = rho[:5, :5]\n",
    "rho_g2  = rho[5:, 5:]\n",
    "rho_g12 = rho[:5, 5:]\n",
    "\n",
    "print(rho_g1.shape)\n",
    "print(rho_g2.shape)\n",
    "print(rho_g12.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average within / cross group correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within G1   0.8650795342544025\n",
      "within G2   0.9895104895104896\n",
      "cross G1-G2 -0.7177393166325814\n"
     ]
    }
   ],
   "source": [
    "idx = np.triu_indices(5, 1)\n",
    "print(\"within G1  \", np.mean(rho_g1[idx]))\n",
    "\n",
    "idx = np.triu_indices(4, 1)\n",
    "print(\"within G2  \", np.mean(rho_g2[idx]))\n",
    "\n",
    "print(\"cross G1-G2\", np.mean(rho_g12[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Question 04 <a name=\"Q04\"></a>\n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4 (40 points)**. Clustering with LSA\n",
    "\n",
    "1. Begin by loading a PubMed database of selected article titles using 'pickle'. With the following:\n",
    "```import pickle\n",
    "docs = pickle.load(open('data/pubmed.pic', 'rb'))```\n",
    "\n",
    "    Create a tf-idf matrix for every term that appears at least once in any of the documents. What is the shape of the tf-idf matrix? \n",
    "\n",
    "2. Perform SVD on the tf-idf matrix to obtain $U \\Sigma V^T$ (often written as $T \\Sigma D^T$ in this context with $T$ representing the terms and $D$ representing the documents). If we set all but the top $k$ singular values to 0, the reconstructed matrix is essentially $U_k \\Sigma_k V_k^T$, where $U_k$ is $m \\times k$, $\\Sigma_k$ is $k \\times k$ and $V_k^T$ is $k \\times n$. Terms in this reduced space are represented by $U_k \\Sigma_k$ and documents by $\\Sigma_k V^T_k$. Reconstruct the matrix using the first $k=10$ singular values.\n",
    "\n",
    "3. Use agglomerative hierarchical clustering with complete linkage to plot a dendrogram and comment on the likely number of  document clusters with $k = 100$. Use the dendrogram function from [SciPy ](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html).\n",
    "\n",
    "4. Determine how similar each of the original documents is to the new document `data/mystery.txt`. Since $A = U \\Sigma V^T$, we also have $V = A^T U S^{-1}$ using orthogonality and the rule for transposing matrix products. This suggests that in order to map the new document to the same concept space, first find the tf-idf vector $v$ for the new document - this must contain all (and only) the terms present in the existing tf-idx matrix. Then the query vector $q$ is given by $v^T U_k \\Sigma_k^{-1}$. Find the 10 documents most similar to the new document and the 10 most dissimilar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q40 Download pubmed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes on the Pubmed articles**\n",
    "\n",
    "These were downloaded with the following script.\n",
    "\n",
    "```python\n",
    "from Bio import Entrez, Medline\n",
    "Entrez.email = \"YOUR EMAIL HERE\"\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    docs = pickle.load(open('data/pubmed.pic', 'rb'))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    docs = {}\n",
    "    for term in ['plasmodium', 'diabetes', 'asthma', 'cytometry']:\n",
    "        handle = Entrez.esearch(db=\"pubmed\", term=term, retmax=50)\n",
    "        result = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        idlist = result[\"IdList\"]\n",
    "        handle2 = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\")\n",
    "        result2 = Medline.parse(handle2)\n",
    "        for record in result2:\n",
    "            title = record.get(\"TI\", None)\n",
    "            abstract = record.get(\"AB\", None)\n",
    "            if title is None or abstract is None:\n",
    "                continue\n",
    "            docs[title] = '\\n'.join([title, abstract])\n",
    "            print title\n",
    "        handle2.close()\n",
    "    pickle.dump(docs, open('data/pubmed.pic', 'wb'))\n",
    "docs.values()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%Bash\n",
    "cat > \n",
    "from Bio import Entrez, Medline\n",
    "Entrez.email = \"YOUR EMAIL HERE\"\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    docs = pickle.load(open('data/pubmed.pic', 'rb'))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    docs = {}\n",
    "    for term in ['plasmodium', 'diabetes', 'asthma', 'cytometry']:\n",
    "        handle = Entrez.esearch(db=\"pubmed\", term=term, retmax=50)\n",
    "        result = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        idlist = result[\"IdList\"]\n",
    "        handle2 = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\")\n",
    "        result2 = Medline.parse(handle2)\n",
    "        for record in result2:\n",
    "            title = record.get(\"TI\", None)\n",
    "            abstract = record.get(\"AB\", None)\n",
    "            if title is None or abstract is None:\n",
    "                continue\n",
    "            docs[title] = '\\n'.join([title, abstract])\n",
    "            print title\n",
    "        handle2.close()\n",
    "    pickle.dump(docs, open('data/pubmed.pic', 'wb'))\n",
    "docs.values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
